{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must import the needed modules to load and work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data containing users confusion matrices, and prior information on each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retired_images = loadmat('retired_images.mat')\n",
    "conf_matrices = loadmat('conf_matrices.mat')\n",
    "PP_matrices = loadmat('PP_matrices.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data into a 'pandas' data structure to make it more functional in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmpPP  = []\n",
    "tmpPP1 = []\n",
    "for iN in range(PP_matrices['PP_matrices'][0].size):\n",
    "    tmpPP.append(PP_matrices['PP_matrices'][0][iN]['imageID'][0][0])\n",
    "    tmpPP1.append( PP_matrices['PP_matrices'][0][iN]['matrix'])\n",
    "\n",
    "\n",
    "tmpCM  = []\n",
    "tmpCM1 = []\n",
    "for iN in range(conf_matrices['conf_matrices'].size):\n",
    "    tmpCM.append(conf_matrices['conf_matrices'][iN]['userID'][0][0][0])\n",
    "    tmpCM1.append(conf_matrices['conf_matrices'][iN]['conf_matrix'][0])\n",
    "\n",
    "\n",
    "tmpRI  = []\n",
    "for iN in range(retired_images['retired_images'].size):\n",
    "    tmpRI.append(retired_images['retired_images'][0][iN]['imageID'][0][0])\n",
    "\n",
    "\n",
    "conf_matrices  = pd.DataFrame({ 'userID' : tmpCM,'conf_matrix' : tmpCM1})\n",
    "retired_images = pd.DataFrame({ 'imageID' : tmpRI})\n",
    "PP_matrices    = pd.DataFrame({ 'imageID' : tmpPP,'pp_matrix' : tmpPP1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format image batches into 'pandas' data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    batch_name = 'batch' + str(i) + '.mat' #batch1.mat, batch2.mat, etc\n",
    "    batch = loadmat(batch_name) #read batch file\n",
    "    tmpType         = []\n",
    "    tmpLabels       = []\n",
    "    tmpuserIDs      = []\n",
    "    tmpTruelabel    = []\n",
    "    tmpImageID      = []\n",
    "    tmpML_posterior = []\n",
    "    # Subtracting 1 off the index from the mat file for the \"labels\" so that the indexing works in python. \n",
    "    for iN in range(batch['images'].size):\n",
    "        tmpType.append(batch['images'][iN]['type'][0][0])\n",
    "        tmpLabels.append(batch['images'][iN]['labels'][0][0]-1)\n",
    "        tmpuserIDs.append(batch['images'][iN]['IDs'][0][0])\n",
    "        tmpTruelabel.append(batch['images'][iN]['truelabel'][0][0][0]-1)\n",
    "        tmpML_posterior.append(batch['images'][iN]['ML_posterior'][0][0])\n",
    "        tmpImageID.append(batch['images'][iN]['imageID'][0][0][0])\n",
    "\n",
    "    images = pd.DataFrame({'type' : tmpType,'labels' : tmpLabels, 'userIDs' : tmpuserIDs, 'ML_posterior' : tmpML_posterior, 'truelabel' : tmpTruelabel, 'imageID' : tmpImageID}) #store formatted data in 'images' structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets talk boout the conf_matrices.mat file that stores the confusion matrices of all the users. This information (stored in a .datfile) will be a NX1 array where N is the number of users. in each row we have a cell array that contains the CXC \"confusion matrix\" for that user. A perfectly skilled user would only have values on the diagonal of this matrix and all off diagonal values indicate wrong answers were given to one category or another when presented with a 'G' true labelled image. To illustrate this we'll print out one users confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191   3   5   2   5   3   3   6   3   1   2   1   1   5   1]\n",
      " [  4 184   1   4   5   4   1   3   5   1   5   4   1   4   5]\n",
      " [  3   3 217   4   2   2   4   2   1   1   3   2   4   3   1]\n",
      " [  4   2   2 213   2   2   4   5   2   1   1   3   4   2   4]\n",
      " [  4   1   2   3 210   4   3   1   1   5   4   5   3   4   2]\n",
      " [  5   1   3   1   2 220   1   5   5   1   5   5   2   4   5]\n",
      " [  5   4   4   3   3   3 181   1   3   1   1   3   3   5   3]\n",
      " [  2   4   5   2   5   5   2 198   4   3   4   4   2   5   1]\n",
      " [  3   1   4   3   4   1   1   5 210   5   5   2   5   4   1]\n",
      " [  4   4   2   4   5   1   1   4   3 188   1   2   1   2   4]\n",
      " [  2   3   5   2   3   5   1   1   1   1 194   5   2   3   4]\n",
      " [  2   1   5   2   3   2   1   2   4   1   4 215   1   5   4]\n",
      " [  1   5   5   5   5   1   1   2   5   4   1   1 213   3   2]\n",
      " [  3   4   5 214   4   2 183 199   1   6   6 216 214   4   5]\n",
      " [  4   4   5   4   3   5   1   3   4   2   5   5   2   3 192]]\n"
     ]
    }
   ],
   "source": [
    "print conf_matrices['conf_matrix'][0] #print confusion matrix of first user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the value in the first row, second column is a 3. This indicates that the user classified 3 images in class 2, when really they should be in class 1. Confusion matrices are used to evaluate users skill level, and are updated as images are retired. \n",
    "\n",
    "Here's a good visualization of the matrix in heat map form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = conf_matrices['conf_matrix'][0]\n",
    "plt.matshow(data, cmap='Blues', norm=colors.LogNorm(vmin=data.min(), vmax=data.max()))\n",
    "plt.colorbar()\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('classes')\n",
    "plt.title('Visualization of confusion matrix')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(0,15,1))\n",
    "ax.set_yticks(np.arange(0,15,1))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking down the diagonal we can see that this user was not the best at classifying images belonging to class 13. If the user were perfect, he or she would have a dark blue diagonal, and whitespace everywhere else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the main function that evaluates the batches of images labeled by users. The Zooniverse server (specifically Nero https://github.com/zooniverse/nero) will continuously send data (image batches) to be evaluated. \n",
    "\n",
    "Lets look at some of that data for one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_posterior    [0.0143179197288, 0.0143179197288, 0.014317919...\n",
      "imageID                                                        30\n",
      "labels          [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...\n",
      "truelabel                                                      -2\n",
      "type                                                            T\n",
      "userIDs         [18, 29, 24, 22, 30, 14, 13, 16, 1, 9, 7, 27, ...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print images.iloc[0,:] #accesses all of the first images information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, thats a lot of information for one image. Lets breakdown what this data actually stores, and how to access certain parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID of the users, the ID of the image they classified, and \n",
    "the classification made by that user for that image are all held in the 'images' structure. Lets access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30 \n",
      "\n",
      "[18 29 24 22 30 14 13 16  1  9  7 27 23  2 21 11 12 15 28  5 25  8 20]\n",
      "[18 29 24 22 30 14 13 16  1  9  7 27 23  2 21 11 12 15 28  5 25  8 20] \n",
      "\n",
      "[13 13 13 13 13 13 13 13 13 13 13 13 13 13  2 12  5 12 10  4 10  4 11]\n",
      "[13 13 13 13 13 13 13 13 13 13 13 13 13 13  2 12  5 12 10  4 10  4 11] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sample_ImageID = images.iloc[0,:]['imageID']\n",
    "Sample_UserIDs = images.iloc[0,:]['userIDs']\n",
    "Sample_labels = images.iloc[0,:]['labels']\n",
    "\n",
    "print Sample_ImageID\n",
    "print images['imageID'][0], \"\\n\" \n",
    "\n",
    "print Sample_UserIDs\n",
    "print images['userIDs'][0], \"\\n\"\n",
    "\n",
    "print Sample_labels\n",
    "print images['labels'][0], \"\\n\"\n",
    "\n",
    "#Two different ways to access the same image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number is the Image ID corresponding to a specific image.\n",
    "\n",
    "The second array holds the user ID's that have classified the image.\n",
    "\n",
    "The third array holds the classifications made by the users corresponding (one to one) to the second array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'images' structure also contains an images Type, Machine Learning (ML) Posterior, and a True label for each image:\n",
    "\n",
    "THE TYPE - A label (string) either 'T' or 'G' to determine if it is a ML classified label ('T') or a pre-labelled \"golden\" image ('G')\n",
    "\n",
    "ML POSTERIOR- An array (double) of a  1XC row vector where C is the number of pre-determined morphologies that the classifier has been trained on. Each column is the ML confidence (percentage) that the image belongs in one of the C classes.\n",
    "\n",
    "TRUE LABEL - (int) For images labelled 'T' this values is set to -1 but for images labelled 'G' This value indicates the \"true\" class that this image belongs in for the purposes of comparing a citizens classification with this true label.\n",
    "\n",
    "Lets access these elements of 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "T \n",
      "\n",
      "[ 0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.79954912  0.01431792]\n",
      "[ 0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.79954912  0.01431792] \n",
      "\n",
      "-2\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "Sample_type = images.iloc[0,:]['type']\n",
    "Sample_ML_Posterior = images.iloc[0,:]['ML_posterior']\n",
    "Sample_TrueLabel = images.iloc[0,:]['truelabel']\n",
    "\n",
    "print Sample_type\n",
    "print images['type'][0], \"\\n\"\n",
    "\n",
    "print Sample_ML_Posterior\n",
    "print images['ML_posterior'][0], \"\\n\"\n",
    "\n",
    "print Sample_TrueLabel\n",
    "print images['truelabel'][0]\n",
    "\n",
    "#Two different ways to access the same image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does all this information mean?\n",
    "\n",
    "This image has type 'T', meaning it is NOT a golden image and is still in testing.\n",
    "\n",
    "From the ML_Posterior, we can see that the Machine is 79.95% sure this image is in the 14th class, and  1.43% sure it is in each other class.\n",
    "\n",
    "A true label of -2 means this image is still testing and has not been assigned a class.\n",
    "\n",
    "Now that we understand the structure of 'images' and how to access specific image information, lets move on to evaluating image and user classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize R_lim, the limit on how many people can look at an image before it is passed onto a higher skill level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_lim = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize N, the number of images in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = images['type'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize C, the number of morphologies (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " for i in range(N):\n",
    "        if images['type'][i] == 'T':\n",
    "            C = images['ML_posterior'][i].size\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a flat prior. Essentially this means before any more information is known, we assume each image has an equal probability of being in each of the 15 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors = np.ones((1,C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize varaible t. \n",
    "\n",
    "t is a CX1 column vector where C is the number of pre-determined morphologies and where each row is the predetermined certainty threshold that an image must surpass to be considered part of class C. Here all classes have the same threshold but in realty different categories will have more difficult or more relaxed thresholds for determination of class and, as a result, \n",
    "retirability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = .4*np.ones((C,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a decision matrix that holds the decision for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " dec_matrix = np.zeros((1,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a class matrix that holds the True labels of each image. (corresponds one to one to decision matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_matrix = np.zeros((1,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a list to hold the pp_matrices for each images. We'll talk about the importance of pp_matrices later. Note that pp_matrix and posterior matrix may be used interchangeably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp_matrices_rack = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at how a decision for an image is made. The decider function takes in an images posterior matrix, Machine learning decision, number of annotators, and R_lim as arguments, and uses that information to decide the next step for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decider(pp_matrix, ML_dec, t, R_lim, num_annotators): #define the decider function with given arguments\n",
    "    pp_matrix2 = np.hstack((pp_matrix, ML_dec.reshape((15,1)))) #Include ML_decision in posterior matrix\n",
    "    v = np.sum(pp_matrix2, axis=1)/np.sum(np.sum(pp_matrix)) #create vector of normalized sums of pp_matrix2 \n",
    "    maximum = np.amax(v) #initialize maximum, max value of v\n",
    "    maxIdx = np.argmax(v) #initialize maxIdx, index of max value of v\n",
    "\n",
    "    if maximum >= t[maxIdx]: #if maximum is above threshold for that specific class\n",
    "\n",
    "        decision = 1 #retire the image\n",
    "        print('Image is retired')\n",
    "\n",
    "    elif num_annotators >= R_lim: #if more than R_lim annotators have looked at image and no decision reached\n",
    "\n",
    "        decision = 2 #pass image on to next user skill class\n",
    "        print('Image is given to the upper class')\n",
    "\n",
    "    else: #if fewer than R_lim annotators have looked at image\n",
    "\n",
    "        decision = 3 #keep image in same class\n",
    "        print('More labels are needed for the image')\n",
    "\n",
    "    image_class = maxIdx #set image_class \n",
    "\n",
    "    return decision, image_class #return the decision, and image class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chunk of code is used to update users confusion matrices, images posterior matrices (PP_matrix), and to make decisions on the future of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is retired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is from the training set\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "The image is from the training set\n",
      "The image is from the training set\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n",
      "Image is retired\n"
     ]
    }
   ],
   "source": [
    "for i in range(N):\n",
    "\n",
    "        if images['type'][i] == 'G': #check if golden set image\n",
    "            labels  = images['labels'][i] #take citizen labels of image\n",
    "            userIDs = images['userIDs'][i] #take IDs of citizens who label image\n",
    "            tlabel  = images['truelabel'][i] #take true label of image\n",
    "\n",
    "            for ii in range(userIDs.size): #iterate over user IDs of image\n",
    "\n",
    "                indicator = 0 #initialize indicator to zero \n",
    "\n",
    "                for cc in range(len(conf_matrices)): #iterate over confusion matrices\n",
    "\n",
    "                    if userIDs[ii] == conf_matrices['userID'][cc]: #if user is already registered\n",
    "\n",
    "                        conf_matrix = conf_matrices['conf_matrix'][cc] #take confusion matrix of citizen\n",
    "                        conf_matrix[tlabel,labels[ii]] += 1 #update confusion matrix\n",
    "                        conf_matrices['conf_matrix'][cc] = conf_matrix #confusion matrix put back in stack\n",
    "                        indicator = 1\n",
    "\n",
    "                if indicator == 0: #if user not registered\n",
    "\n",
    "                    dummy_matrix = np.zeros((C,C)) #create dummy matrix\n",
    "                    dummy_matrix[tlabel,labels[ii]] += 1 #update dummy matrix\n",
    "                    tmp = pd.DataFrame({ 'userID' : [userIDs[ii]],'conf_matrix' : [dummy_matrix]},index = [len(conf_matrices)]) #create new users confusion matrix\n",
    "                    conf_matrices = conf_matrices.append(tmp) #append new users confusion matrix to stack\n",
    "\n",
    "            dec_matrix[0,i] = 0 #since it is a training image, no decision is made\n",
    "            class_matrix[0,i] = tlabel #class of image is its true label\n",
    "            print('The image is from the training set')\n",
    "\n",
    "        else: #if image not in golden set, i.e. has ML label but no true label\n",
    "\n",
    "            indicator1 = 0\n",
    "\n",
    "            for kk in range(retired_images.size): #loop over retired images\n",
    "\n",
    "                if images['imageID'][i] == retired_images['imageID'][kk]: #if image is retired\n",
    "                    indicator1 = 1\n",
    "                    dec_matrix[0,i] = -1 #give invalid decision\n",
    "                    break\n",
    "\n",
    "            if indicator1 == 0: #if image is not retired\n",
    "\n",
    "                labels           = images['labels'][i] #take citizen labels of image\n",
    "                userIDs          = images['userIDs'][i] #take IDs of citizens who label image\n",
    "                num_annotators   = labels.size #define number of citizens who annotate image\n",
    "                ML_dec           = images['ML_posterior'][i] #take ML posteriors of image\n",
    "                imageID          = images['imageID'][i] #take ID of image\n",
    "                image_prior      = priors #set priors for image to original priors\n",
    "\n",
    "                for y in range(len(PP_matrices)): #iterate over posterior matrices\n",
    "\n",
    "                    if imageID == PP_matrices['imageID'][y]: #find posterior matrix for the image\n",
    "                        image_prior = np.sum(PP_matrices['pp_matrix'][y],axis=1)/np.sum(PP_matrices['pp_matrix'][y]) #if image labeled but not retired, PP_matrix information is used in the place of priors\n",
    "                        break\n",
    "\n",
    "                for k in range(num_annotators): #iterate over citizens that labeled image\n",
    "                    for iN in range(len(conf_matrices)): #iterate over confusion matrices\n",
    "\n",
    "                        if userIDs[k] == conf_matrices['userID'][iN]: #find confusion matrix corresponding to citizen\n",
    "                            \n",
    "                            conf = conf_matrices['conf_matrix'][iN] #take confusion matrix of citizen\n",
    "                            break\n",
    "\n",
    "                    conf_divided,x,z,s = np.linalg.lstsq(np.diag(sum(conf,2)),conf) #calculate p(l|j) value\n",
    "\n",
    "                    for j in range(C): #iterate over classes\n",
    "\n",
    "                        pp_matrix = np.zeros((C,num_annotators)) #create posterior matrix\n",
    "                        pp_matrix[j,k] = (conf_divided[j,labels[k]]*priors[0][j])/sum(conf_divided[:,labels[k]]*priors[0]) #calculate posteriors\n",
    "                pp_matrices_rack.append(pp_matrix) #assign values to pp_matrices_rack\n",
    "\n",
    "\n",
    "                dec_matrix[0,i], class_matrix[0,i] = decider(pp_matrix, ML_dec, t, R_lim, num_annotators) #make decisions for each image in batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now lets take a look at how the decider function works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is given to the upper class\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pp_matrix2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7d7165d935b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdecider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_matrix_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mML_dec_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_lim_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_annotators_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#call decider function with sample arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpp_matrix2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pp_matrix2' is not defined"
     ]
    }
   ],
   "source": [
    "#Sample arguments for decider function \n",
    "pp_matrix_sample = PP_matrices['pp_matrix'][0]\n",
    "ML_dec_sample = np.array([.1, .05, .05, .05, .05, .6, .001, .014, .1, .002, .005, .0002, 0, 0, 0])\n",
    "R_lim_sample = 20\n",
    "no_annotators_sample = len(PP_matrices['pp_matrix'][0][0])\n",
    "\n",
    "\n",
    "\n",
    "decider(pp_matrix_sample, ML_dec_sample, t, R_lim_sample, no_annotators_sample) #call decider function with sample arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
