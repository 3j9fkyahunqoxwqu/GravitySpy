{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must import the needed modules to load and work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data containing user information, including their confusion matrix, and prior information on each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_labels = loadmat('true_labels.mat')\n",
    "retired_images = loadmat('retired_images.mat')\n",
    "conf_matrices = loadmat('conf_matrices.mat')\n",
    "PP_matrices = loadmat('PP_matrices.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets talk boout the conf_matrices.mat file, that stores the confusion matrices of all the users. This information (stored in a .datfile) will be a NX1 array where N is the number of users. in each row we have a cell array that contains the CXC \"confusion matrix\" for that user. A perfectly skilled user would only have values on the diagonal of this matrix and all off diagonal values indicate wrong answers were given to one category or another when presented with a 'G' true labelled image. To illustrate this we'll print out a users confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191   3   5   2   5   3   3   6   3   1   2   1   1   5   1]\n",
      " [  4 184   1   4   5   4   1   3   5   1   5   4   1   4   5]\n",
      " [  3   3 217   4   2   2   4   2   1   1   3   2   4   3   1]\n",
      " [  4   2   2 213   2   2   4   5   2   1   1   3   4   2   4]\n",
      " [  4   1   2   3 210   4   3   1   1   5   4   5   3   4   2]\n",
      " [  5   1   3   1   2 220   1   5   5   1   5   5   2   4   5]\n",
      " [  5   4   4   3   3   3 181   1   3   1   1   3   3   5   3]\n",
      " [  2   4   5   2   5   5   2 198   4   3   4   4   2   5   1]\n",
      " [  3   1   4   3   4   1   1   5 210   5   5   2   5   4   1]\n",
      " [  4   4   2   4   5   1   1   4   3 188   1   2   1   2   4]\n",
      " [  2   3   5   2   3   5   1   1   1   1 194   5   2   3   4]\n",
      " [  2   1   5   2   3   2   1   2   4   1   4 215   1   5   4]\n",
      " [  1   5   5   5   5   1   1   2   5   4   1   1 213   3   2]\n",
      " [  3   4   5 214   4   2 183 199   1   6   6 216 214   4   5]\n",
      " [  4   4   5   4   3   5   1   3   4   2   5   5   2   3 192]]\n"
     ]
    }
   ],
   "source": [
    "print conf_matrices['conf_matrices'][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the value in the first row, second column is a 3. This indicates that the user classified 3 images in class 2, when really they should be in class 1. Confusion matrices are used to evaluate users skill level, and updated as images are retired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the main function that evaluates the batches of images labeled by users. The Zooniverse server (specifically Nero https://github.com/zooniverse/nero) will continuously send data (batches) to be evaluated. \n",
    "\n",
    "Lets load in and print some of that data using the loadmat function we imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'T']\n"
     ]
    }
   ],
   "source": [
    "batch = loadmat('batch1.mat')\n",
    "print batch['images'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, thats a lot of information for one image. Lets breakdown what these data 'batches' actually store, and how to access certain parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID of the users, the ID of the image they classified, and \n",
    "the classification made by that user for that image are all held in the batches. Lets access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[18 29 24 22 30 14 13 16  1  9  7 27 23  2 21 11 12 15 28  5 25  8 20]\n",
      "[14 14 14 14 14 14 14 14 14 14 14 14 14 14  3 13  6 13 11  5 11  5 12]\n"
     ]
    }
   ],
   "source": [
    "Sample_ImageID = batch['images'][0]['imageID'][0][0][0]\n",
    "Sample_UserIDs = batch['images'][0]['IDs'][0][0]\n",
    "Sample_classifications = batch['images'][0]['labels'][0][0]\n",
    "\n",
    "print Sample_ImageID\n",
    "print Sample_UserIDs\n",
    "print Sample_classifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number is the Image ID of a specific image.\n",
    "\n",
    "The second array holds the user ID's that classified the image.\n",
    "\n",
    "The third array holds the classifications of the image made by the users corresponding (one to one) to the second array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batches also contain an images Type, Machine Learning (ML) Posterior, and a True label:\n",
    "\n",
    "The Type - A label (string) either 'T' or 'G' to determine if it is a ML classified label ('T') or a pre-labelled \"golden\" image ('G')\n",
    "\n",
    "ML Posterior - An array (double) of a  1XC row vector where C is the number of pre-determined morphologies that the classifier has been trained on. Each column is the ML confidence (percentage) that the image belongs in one of the C classes.\n",
    "\n",
    "True Label - (int) For images labelled 'T' this values is set to -1 but for images labelled 'G' This value indicates the \"true\" class that this image belongs in for the purposes of comparing a citizens classification with this true label.\n",
    "\n",
    "Lets access these elements of the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "[ 0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792  0.01431792\n",
      "  0.01431792  0.79954912  0.01431792]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "Sample_type = batch['images'][0]['type'][0][0]\n",
    "Sample_ML_Posterior = batch['images'][0]['ML_posterior'][0][0]\n",
    "Sample_TrueLabel = batch['images'][0]['truelabel'][0][0][0]\n",
    "\n",
    "print Sample_type\n",
    "print Sample_ML_Posterior\n",
    "print Sample_TrueLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does all this information mean?\n",
    "\n",
    "This image has type 'T' meaning it is not a golden image and is still in testing.\n",
    "\n",
    "From the ML_Posterior, we can see that the Machine is 79.95% sure this image is in the 14th class, and  1.43% sure it is in each other class.\n",
    "\n",
    "A true label of -1 means this image is still testing and has not been assigned a class.\n",
    "\n",
    "Now that we understand the structure of each batch and how to access specific information within the batches, lets move on to evaluating image and user classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, lets set a flat prior for each image. This means that before more information is analyzed, we are giving an equal chance that the image is in each of the 15 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_labels = np.histogram((true_labels['true_labels'][0]),np.unique(true_labels['true_labels'][0]))\n",
    "priors = no_labels[1]/len(true_labels['true_labels'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize R_lim, the limit on how many people can look at an image before it is passed onto a higher skill level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_lim = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize N, the number of images in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(batch['images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize C, the number of morphologies (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    if batch['images'][i][0][0] == 'T':\n",
    "        C = len(batch['images'][i]['ML_posterior'][0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize varaible t. t is a CX1 column vector where C is the number of pre-determined morphologies and where each row is the predetermined certainty threshold that an image most surpass to be considered part of class C. Here all classes have the same threshold but in realty different categories will have more difficult or more relax thresholds for determination of class and, as a result, \n",
    "retirability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = .4*np.ones((C,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a decision matrix that holds the decision for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " dec_matrix = np.zeros((1,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a class matrix that holds the True labels of each image. (corresponds one to one to decision matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_matrix = np.zeros((1,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize a list to hold the pp_matrices for each images. We'll talk about the importance of pp_matrices later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp_matrices_rack = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chunk of code is used to update users confusion matrices, images posterior matrices (PP_matrix), and to make decisions on the fate of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(N): #For each image in the batch\n",
    "\n",
    "    if batch['images'][i]['type'][0][0] == 'G': #check if image is in golden set\n",
    "        labels = batch['images'][i]['labels'][0][0] #take citizen labels of image\n",
    "        userIDs = batch['images'][i]['IDs'][0][0] #take IDs of citizens who labeled the image\n",
    "        tlabel = batch['images'][i]['truelabel'][0][0][0] #take true label of image\n",
    "\n",
    "        for ii in range(len(userIDs)): #For each user \n",
    "\n",
    "            indicator = 0 #initialize indicator to zero for each user\n",
    "\n",
    "            for cc in range(len(conf_matrices['conf_matrices'][0])): #for each users confusion matrix\n",
    "\n",
    "                if userIDs[ii] == conf_matrices['conf_matrices'][cc]['userID'][0][0][0]: #if user already has a confusion matrix\n",
    "\n",
    "                    conf_matrix = conf_matrices['conf_matrices'][cc]['conf_matrix'][0] #take confusion matrix of citizen\n",
    "                    conf_matrix[tlabel-1,labels[ii]-1] += 1 #update confusion matrix, rewarding user for correct classification\n",
    "                    conf_matrices['conf_matrices'][cc]['conf_matrix'][0] = conf_matrix #confusion matrix put back in stack\n",
    "                    indicator = 1 #user is already registered\n",
    "\n",
    "            if indicator == 0: #if user not registered\n",
    "\n",
    "                dummy_matrix = np.zeros((C,C)) #create dummy confusiong matrix\n",
    "                dummy_matrix[tlabel-1,labels[ii]-1] += 1 #update dummy matrix, rewarding user for correct classification\n",
    "                #conf_matrices['conf_matrices'] = np.append(conf_matrices['conf_matrices'][0], dummy_matrix) #append to confusion matrices\n",
    "                #conf_matrices(end + 1).userID = IDs(ii)\n",
    "\n",
    "        dec_matrix[0,i] = 0 #Since image is golden, no decision needs to be made about the image\n",
    "        class_matrix[0,i] = tlabel #class of image is its true label\n",
    "        print('The image is from the training set')\n",
    "\n",
    "    else: #if image not in golden set, i.e. has ML label but no true label\n",
    "\n",
    "        indicator1 = 0 #initialize indicator1 to zero\n",
    "\n",
    "        for kk in range(len(retired_images['retired_images'][0])): #for each retired image\n",
    "\n",
    "            if batch['images'][i]['imageID'][0][0][0] == retired_images['retired_images'][0][kk]['imageID'][0][0]: #if image is already retired\n",
    "\n",
    "                indicator1 = 1 #set indicator1 to one, meaning image has already been retired\n",
    "                dec_matrix[0,i] = -1 #give invalid decision\n",
    "\n",
    "        if indicator1 == 0: #if image has not already been retired\n",
    "\n",
    "            labels = batch['images'][i]['labels'][0][0] #take citizen labels of image\n",
    "            userIDs = batch['images'][i]['IDs'][0][0] #take IDs of citizens who label image\n",
    "            no_annotators = len(labels) #take number of citizens who labeled the image\n",
    "            ML_dec = batch['images'][i]['ML_posterior'][0][0] #take ML posteriors of image\n",
    "            imageID = batch['images'][i]['imageID'][0][0][0] #take ID of image\n",
    "            image_prior = priors #set priors for image to original priors\n",
    "\n",
    "            for y in range(len(PP_matrices['PP_matrices'][0])): #for each images posterior matrix\n",
    "\n",
    "                if imageID == PP_matrices['PP_matrices'][0][y]['imageID'][0][0]: #If image already has a posterior matrix\n",
    "\n",
    "                    image_prior = np.sum(PP_matrices['PP_matrices'][0][y]['matrix'],axis=1)/np.sum(PP_matrices['PP_matrices'][0][y]['matrix']) #Use posterior matrix information to update an images prior\n",
    "\n",
    "            for j in range(C): #for each class\n",
    "\n",
    "                for k in range(no_annotators): #for each citizen that labeled image\n",
    "\n",
    "                    for iN in range(len(conf_matrices['conf_matrices'][0])): #for each confusion matrix\n",
    "                \n",
    "                        if userIDs[k] == conf_matrices['conf_matrices'][iN]['userID'][0][0][0]: #If citizen already has a confusion matrix\n",
    "\n",
    "                            conf = conf_matrices['conf_matrices'][iN]['conf_matrix'][0] #take confusion matrix of citizen\n",
    "                            conf_divided = np.diag(sum(conf,2))/conf #calculate p(l|j) value\n",
    "                            pp_matrix = np.zeros((C,no_annotators)) #create posterior matrix\n",
    "                            pp_matrix[j,k] = ((conf_divided[j,(labels[k])])*priors[j])/sum(conf_divided[:,(labels[k])]*priors) #Fill posterior matrix with values\n",
    "                            pp_matrices_rack.append(pp_matrix) #put PP_matrix in the rack\n",
    "\n",
    "                break\n",
    "\n",
    "        dec_matrix[0,i], class_matrix[0,i] = decider(pp_matrix, ML_dec, t, R_lim, no_annotators) #make decisions for each image in batch using decider function.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at how a decision for an image is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decider(pp_matrix, ML_dec, t, R_lim, no_annotators): #define the decider function with given arguments\n",
    "    pp_matrix2 = np.append(pp_matrix, ML_dec.reshape((15,1))) #Include ML_decision in posterior matrix\n",
    "    v = np.sum(pp_matrix2, axis=1)/np.sum(pp_matrix) #create vector of normalized sums of pp_matrix2 \n",
    "    maximum = np.amax(v) #initialize maximum, max value of v\n",
    "    maxIdx = np.argmax(v) #initialize maxIdx, index of max value of v\n",
    "\n",
    "    if maximum >= t[maxIdx]: #if maximum is above threshold for that specific class\n",
    "\n",
    "        decision = 1 #retire the image\n",
    "        print('Image is retired')\n",
    "\n",
    "    elif no_annotators >= R_lim: #if more than R_lim annotators have looked at image and no decision reached\n",
    "\n",
    "        decision = 2 #pass image on to next user skill class\n",
    "        print('Image is given to the upper class')\n",
    "\n",
    "    else: #if fewer than R_lim annotators have looked at image\n",
    "\n",
    "        decision = 3 #keep image in same class\n",
    "        print('More labels are needed for the image')\n",
    "\n",
    "    image_class = maxIdx #set image_class \n",
    "\n",
    "    return decision, image_class #return the decision, and image class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
