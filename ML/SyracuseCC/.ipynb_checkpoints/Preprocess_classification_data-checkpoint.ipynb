{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocess human classification data downloaded from Zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The human classification data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the more important columns in the exported data are in JSON format: the subject and the annotations. So, some simple scripts to extract the relevant data. Unfortunately, the JSON seems to have changed over time, so the functions have to be flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ID_from_subject_data(subject_data):\n",
    "    # given a string of JSON representing the subject data, extract and return the ID\n",
    "    sd = json.loads(subject_data)\n",
    "    sd1 = list(sd.values())[0]\n",
    "    sd1k = sd1.keys()\n",
    "    if 'ID' in sd1k:\n",
    "        # easiest case: there's a subject ID in the JSON\n",
    "        v = sd1['ID']\n",
    "    elif 'Filename1' in sd1k:\n",
    "        # otherwise, we can get it from the filename (I hope)\n",
    "        v = sd1['Filename1'][3:13]\n",
    "    else:\n",
    "        # about 28 case where the subject data are in some weird format that this doesn't catch, which we ignore\n",
    "        v = ''\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6705d11ec6c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# an example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mID_from_subject_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m40000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_data' is not defined"
     ]
    }
   ],
   "source": [
    "# an example\n",
    "ID_from_subject_data(classification_data['subject_data'][40000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_need to check that this is really working reliably given the number of observations that don't connect_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def user_choice_from_annotations(annotations):\n",
    "    # given a string of JSON representing the annotation, extract and return the user's annotation\n",
    "    a = json.loads(annotations)\n",
    "\n",
    "    # not all users actually recorded a choice\n",
    "    try:\n",
    "        v = a[0]['value'][0]['choice']\n",
    "    except (IndexError, KeyError): \n",
    "        # volunteer apparently didn't pick anything \n",
    "        v = ''\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example\n",
    "user_choice_from_annotations(classification_data['annotations'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data downloaded from Zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_data = pd.read_csv('160626 gravity-spy-classifications.csv',parse_dates=[7,],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(classification_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns to the data frame with the extracted data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_data['subject_ID'] = classification_data['subject_data'].map(ID_from_subject_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_data['annotation'] = classification_data['annotations'].map(user_choice_from_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncaught cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_data[classification_data.subject_ID == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few sample statistics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_by_user = classification_data.groupby('user_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_by_user['user_ip'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_data.groupby('annotation').count()['classification_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glitch classes\n",
    "The coding for the classes is different in the ML and Human classification, so a file to translate between them. Also, there are multiple codes for the same glitch class in the human file, so some lines have repeats. I marked a preferred code in case we ever want to move from the ML data to the code in Gravity Spy. Note that pandas can't handle an NA in an integer column, which is why Model_number is a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glitch_classes = pd.read_csv('glitch-classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glitch_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use: make the mean confidences more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_scores = ML_data.loc[:,['label','confidence']].groupby('label').agg([np.mean,len])\n",
    "mean_scores['MLID'] = mean_scores.index\n",
    "mean_scores = pd.merge(mean_scores, glitch_classes[glitch_classes.Preferred==1], on='MLID')\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ML labels to classification data\n",
    "Merge the human data with the translation to the ML coding system and drop most of the columns. I chose to keep user_id instead of user_name in an attempt to make the data more private. It occurs to me that we should filter out internal users who've been debugging or doing demos, but I was assured that they all were serious. Still, the learning parameters are probably different. There are 51224 classifications in total but 27 without a subject_ID due to the problem mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_data_cols = ['user_id', 'subject_ID', 'created_at', 'annotation', 'workflow_id', 'workflow_version']\n",
    "human_data = pd.merge(classification_data.loc[classification_data.annotation!='', human_data_cols], \\\n",
    "                      glitch_classes, left_on='annotation', right_on='HCID')\n",
    "human_data.drop(['annotation','HCID','Preferred'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(human_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications_store = pd.HDFStore('160626 data.h5')\n",
    "# classifications_store['classification_data'] = classification_data\n",
    "del classifications_store['human_data']\n",
    "classifications_store['human_data'] = human_data\n",
    "classifications_store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
